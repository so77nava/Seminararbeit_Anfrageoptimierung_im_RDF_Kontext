\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{csquotes}
\usepackage[style=numeric]{biblatex}
\addbibresource{literatur.bib}
\usepackage{listings}
\lstset{
  basicstyle=\ttfamily,
  breaklines=true,
  frame=single
  language=SPARQL,
  morekeywords={SELECT, WHERE, FILTER, ORDER BY, DESC, OPTIONAL, UNION, CONSTRUCT, ASK, DESCRIBE, GRAPH, BIND, VALUES, SERVICE},
}


\title{Anfrageoptimierung im RDF-Kontext}
\author{Samuel Jordan Ouabo}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

% ---------------------- Kapitel 1 ------------------------
\section{Einleitung}

Das World Wide Web hat sich in den letzten Jahrzehnten grundlegend gewandelt: Von einer rein hypertextbasierten Dokumentensammlung hin zu einem semantisch vernetzten Informationsraum, der nicht nur für Menschen, sondern auch für Maschinen interpretierbar ist. Diese Entwicklung mündet in der Vision des \textit{Semantic Web}, wie sie von Berners-Lee formuliert wurde – ein Web, in dem Daten nicht nur dargestellt, sondern auch verarbeitet und logisch verknüpft werden können \cite{berners2001semantic}.

Ein zentrales Element des Semantic Web ist das \textit{Resource Description Framework (RDF)}, das Daten in Form von sogenannten Tripeln repräsentiert. Jedes Tripel besteht aus Subjekt, Prädikat und Objekt und bildet damit eine atomare Aussage über eine Ressource. In der Praxis entstehen durch RDF große, heterogene Graphstrukturen – sogenannte Wissensgraphen –, die in Bereichen wie Linked Data, Bioinformatik, maschinelles Lernen oder öffentliche Verwaltung eingesetzt werden \cite{hogan2021knowledge}. Zur Abfrage solcher Graphen dient die standardisierte Sprache \textit{SPARQL}, die auf dem Prinzip des \textit{Graph Pattern Matching} basiert.

Mit der wachsenden Verbreitung von RDF-basierten Datenbanken (auch als Triple Stores bezeichnet) stellt sich zunehmend die Frage, wie solche Systeme performant und skalierbar Anfragen verarbeiten können. Anders als relationale Datenbanksysteme verfügen RDF-Stores jedoch über keine feste Schemadefinition, sondern arbeiten unter der \textit{Open World Assumption} (OWA). Diese Eigenschaften erschweren die Anwendung klassischer Optimierungskonzepte erheblich: Typische Verfahren wie Kostenmodelle, Kardinalitätsschätzungen oder regelbasierte Transformationsstrategien stoßen im RDF-Kontext häufig an ihre Grenzen \cite{wylot2018rdf, ycy2015}.

Die klassische Datenbankforschung – etwa wie sie von Kemper und Eickler beschrieben wurde – hat über Jahrzehnte eine Vielzahl bewährter Methoden für die relationale Anfrageverarbeitung entwickelt \cite{kemper2022datenbanksysteme}. Zu diesen zählen algebraische Anfragepläne, dynamische Join-Reihenfolgenoptimierung und komplexe Indexierungsstrategien. Diese Techniken bilden einen wichtigen Referenzrahmen für die Frage, inwiefern und unter welchen Bedingungen sie sich auch im semantischen Kontext übertragen oder adaptieren lassen.

Ziel dieser Seminararbeit ist es, einen systematischen Überblick über Optimierungsstrategien im RDF-Kontext zu geben. Dazu werden zunächst die Grundlagen der relationalen Anfrageverarbeitung (Kapitel~\ref{sec:relational}) vorgestellt und mit dem RDF-Datenmodell und SPARQL verglichen (Kapitel~\ref{sec:rdf}). Darauf aufbauend werden die spezifischen Optimierungsprobleme und -ansätze in RDF-Datenbanken analysiert (Kapitel~\ref{sec:probleme} und~\ref{sec:ansaetze}). Abschließend erfolgt eine vergleichende Einordnung klassischer und semantischer Optimierungsprinzipien (Kapitel~\ref{sec:vergleich}) sowie eine kritische Diskussion aktueller Limitationen und zukünftiger Forschungsfragen (Kapitel~\ref{sec:diskussion} und~\ref{sec:fazit}).

% ---------------------- Kapitel 2 ------------------------

\section{Grundlagen relationaler Anfrageverarbeitung}

Die relationale Anfrageverarbeitung bildet das Rückgrat klassischer Datenbanksysteme. Ziel ist es, Anfragen – typischerweise in der Sprache SQL formuliert – unabhängig von der physischen Speicherung effizient auszuführen. Grundlage hierfür ist eine mehrstufige Verarbeitungspipeline, die unter anderem durch Kemper und Eickler systematisch dargestellt wird \cite{kemper2022datenbanksysteme}.

\subsection{Anfragebearbeitungsprozess}

Die Bearbeitung einer SQL-Anfrage erfolgt üblicherweise in drei Hauptphasen:

\begin{enumerate}
    \item \textbf{Anfrageübersetzung:} Die SQL-Anfrage wird in einen sogenannten \emph{algebraischen Anfragebaum} übersetzt. Dieser dient als interne Repräsentation und basiert auf Operatoren der relationalen Algebra (z.\,B. $\sigma$ für Selektion, $\pi$ für Projektion, $\bowtie$ für Join).
    
    \item \textbf{Anfrageoptimierung:} Der Anfragebaum wird durch Transformationen in eine äquivalente, aber effizienter auszuführende Variante überführt. Dies kann regelbasiert (durch algebraische Umformungsregeln) oder kostenbasiert (unter Zuhilfenahme eines Kostenmodells) erfolgen.
    
    \item \textbf{Anfrageausführung:} Der optimierte Anfrageplan wird anschließend vom DBMS durch konkrete Zugriffe auf Tabellen, Indizes und Pufferspeicherstrukturen ausgeführt.
\end{enumerate}

\subsection{Relationale Algebra}

Die relationale Algebra stellt eine formale Grundlage für Anfragen dar. Sie umfasst zentrale Operatoren:

\begin{itemize}
    \item \textbf{Selektion ($\sigma$):} Filtert Tupel auf Basis eines Prädikats, z.\,B. $\sigma_{note > 2.0}(\text{Klausuren})$.
    \item \textbf{Projektion ($\pi$):} Reduziert die Attributmenge, z.\,B. $\pi_{\text{name, note}}(\text{Klausuren})$.
    \item \textbf{Join ($\bowtie$):} Verknüpft zwei Relationen über gemeinsame Attribute, z.\,B. $\text{Studenten} \bowtie_{\text{matrNr}} \text{Klausuren}$.
    \item \textbf{Mengenoperationen:} Union, Differenz und kartesisches Produkt.
\end{itemize}

Die Kombination dieser Operatoren in einem Baum hat großen Einfluss auf die Effizienz – insbesondere, wenn redundante Zwischenresultate vermieden werden.

\subsection{Optimierungsstrategien}

Ziel der Anfrageoptimierung ist es, einen möglichst kostengünstigen Ausführungsplan zu generieren. Dazu kommen zwei Hauptstrategien zum Einsatz:

\begin{itemize}
    \item \textbf{Regelbasierte Optimierung:} Transformation des Anfragebaums anhand äquivalenter Umschreibungen. Beispiele sind das Vorziehen selektiver Operationen (``Selektion vor Join'') oder Projektionsreduktionen zur Verkleinerung der Zwischenergebnisse.
    
    \item \textbf{Kostenbasierte Optimierung:} Hierbei werden Statistiken über Tupelanzahl, Kardinalitäten und Indizes genutzt, um die geschätzten Kosten alternativer Pläne zu bewerten. Das Ziel ist, den optimalen Plan mit minimalem Ressourcenverbrauch auszuwählen.
\end{itemize}

Ein klassisches Beispiel für kostenbasierte Optimierung ist der \emph{System R Optimizer}, der mittels dynamischer Programmierung die optimale Join-Reihenfolge bestimmt \cite{selinger1979access}.

\subsection{Einflussfaktoren auf die Performanz}

Die Ausführungszeit einer Anfrage hängt von zahlreichen Systemaspekten ab:

\begin{itemize}
    \item \textbf{Indexierung:} Beschleunigt den Zugriff auf einzelne Tupel oder Wertebereiche.
    \item \textbf{Buffer Management:} Vermeidet unnötigen Festplattenzugriff durch intelligenten Umgang mit dem Hauptspeicher.
    \item \textbf{Parallelisierung:} Nutzt mehrere CPU-Kerne zur gleichzeitigen Ausführung von Teilplänen.
    \item \textbf{Materialisierung vs. Pipelinierung:} Unterschiedliche Strategien zur Auswertung mehrstufiger Operatorbäume.
\end{itemize}

\subsection{IDB und EDB: Relevanz für Optimierung}

In der Datalog-Theorie wird zwischen der \emph{Extensional Database (EDB)} – also den gespeicherten Basisdaten – und der \emph{Intensional Database (IDB)} – abgeleiteten Daten aus Regeln – unterschieden. Diese Konzepte sind insbesondere bei rekursiven Abfragen relevant.

Beispiel: In einem Regelwerk könnte die transitiv abgeschlossene ``Vorgesetztenbeziehung'' durch rekursive Regeln aus einfachen ``Chef von''-Tripeln berechnet werden – ähnlich wie SPARQL \texttt{PROPERTY PATHS} dies im RDF-Kontext ermöglichen. Optimierungsstrategien müssen in solchen Fällen den Fixpunktalgorithmus berücksichtigen.

% ---------------------- Kapitel 3 ------------------------
\section{RDF \& SPARQL – Datenmodell und Anfrageverarbeitung} \label{sec:rdf}

Das \textit{Resource Description Framework (RDF)} ist ein standardisiertes Datenmodell zur Repräsentation strukturierter Informationen im Web. Es bildet die Grundlage des Semantic Web und ermöglicht die Modellierung von Aussagen über Ressourcen in Form von Tripeln. Die zugehörige Anfragesprache \textit{SPARQL} erlaubt das gezielte Durchsuchen solcher RDF-Graphen und stellt somit das Gegenstück zu SQL im relationalen Kontext dar.

\subsection{RDF: Struktur und Semantik}

RDF beschreibt Informationen durch atomare Aussagen in der Form eines Tripels: \textit{(Subjekt, Prädikat, Objekt)}. Diese Tripel lassen sich als gerichtete, beschriftete Kanten in einem Graphen interpretieren. Subjekt und Objekt sind Ressourcen (identifiziert durch URIs) oder Literale; das Prädikat beschreibt die Beziehung zwischen ihnen.

\begin{lstlisting}[caption=Beispielhafte RDF-Repräsentation einer Einwohnerzahl]
dbr:Erlangen dbo:populationTotal "114257"^^xsd:nonNegativeInteger .
\end{lstlisting}

RDF ist schemalos, kann aber mithilfe von \textit{RDF Schema (RDFS)} und der \textit{Web Ontology Language (OWL)} um Typinformationen, Klassenhierarchien und logische Einschränkungen ergänzt werden. Diese ermöglichen auch Inferenzregeln, wie z.\,B. das automatische Ableiten transitiver Beziehungen \cite{antonellini2015owl}.

\subsection{Open World Assumption (OWA)}

Ein zentrales semantisches Prinzip von RDF ist die \textit{Open World Assumption} (OWA): Das Fehlen einer Aussage bedeutet nicht, dass sie falsch ist – sondern lediglich, dass nichts darüber bekannt ist. Dieses Prinzip steht im Gegensatz zur \textit{Closed World Assumption (CWA)} relationaler Systeme, wo nicht gespeicherte Fakten implizit als falsch betrachtet werden. Die OWA wirkt sich direkt auf Optimierungsstrategien aus, da beispielsweise Filterelimination oder Join-Elimination nicht ohne Weiteres möglich sind.

\subsection{SPARQL: Abfragesprache für RDF}

SPARQL (SPARQL Protocol and RDF Query Language) ist die standardisierte Sprache zur Abfrage von RDF-Daten. SPARQL-Anfragen bestehen aus \textit{Graph Patterns}, die über Variablen definiert werden und mit Tripeln in der Datenbasis abgeglichen werden.

\begin{lstlisting}[caption=SPARQL-Abfrage nach Städten mit mehr als 100.000 Einwohnern]
SELECT ?city ?population WHERE {
  ?city rdf:type dbo:City .
  ?city dbo:country dbr:Germany .
  ?city dbo:populationTotal ?population .
  FILTER (?population > 100000)
}
ORDER BY DESC(?population)
\end{lstlisting}

SPARQL unterstützt vier Haupttypen von Anfragen:
\begin{itemize}
    \item \textbf{SELECT:} Liefert Bindungen für Variablen.
    \item \textbf{ASK:} Gibt einen Wahrheitswert zurück.
    \item \textbf{CONSTRUCT:} Generiert neue RDF-Tripel.
    \item \textbf{DESCRIBE:} Liefert eine Beschreibung einer Ressource.
\end{itemize}

Darüber hinaus erlaubt SPARQL komplexe Konstrukte wie \texttt{OPTIONAL} (äquivalent zu \textit{left outer joins}), \texttt{UNION}, \texttt{FILTER} sowie \texttt{PROPERTY PATHS} zur Navigation in RDF-Graphen.

\subsection{Anfrageverarbeitung in RDF-Datenbanken}

RDF-DBMS (z.\,B. Apache Jena, Virtuoso, Blazegraph) verarbeiten SPARQL-Anfragen in mehreren Schritten:

\begin{enumerate}
    \item \textbf{Parsing:} Die SPARQL-Anfrage wird in eine interne Repräsentation überführt.
    \item \textbf{Optimierung:} Der Anfragebaum wird hinsichtlich Filterplatzierung, Join-Reihenfolge und Pattern-Gruppe analysiert.
    \item \textbf{Ausführung:} Die optimierte Anfrage wird über spezialisierte Speicherstrukturen (z.\,B. Triple Tables, Hexastore) ausgeführt.
\end{enumerate}

Ein zentrales Problem besteht in der \textbf{hohen Joindichte}: Selbst einfache Abfragen erfordern mehrere Joins, da RDF keine Attributtabellen, sondern atomare Aussagen nutzt. Dadurch entstehen viele Kanten im Anfragegraphen – mit teils erheblichem Einfluss auf die Laufzeit.

\subsection{Technische Besonderheiten RDF-basierter Systeme}

Im Gegensatz zu relationalen Datenbanken setzen RDF-Systeme auf spezielle Speicherstrukturen:
\begin{itemize}
    \item \textbf{Triple Table:} Speicherung aller Tripel in einer dreispaltigen Tabelle (Subjekt, Prädikat, Objekt).
    \item \textbf{Vertical Partitioning:} Separate Tabellen je Prädikat zur Effizienzsteigerung.
    \item \textbf{Property Tables:} Gruppierung häufig gemeinsam auftretender Prädikate.
    \item \textbf{Hexastore:} Speicherung aller 6 Permutationen von S-P-O zur Beschleunigung von Joins.
\end{itemize}

Diese Strukturen bestimmen maßgeblich die Optimierbarkeit von SPARQL-Anfragen und beeinflussen sowohl den Planungsaufwand als auch die Ausführungsgeschwindigkeit.

% ---------------------- Kapitel 4 ------------------------
\section{Optimierungsprobleme in RDF-Datenbanken} \label{sec:probleme}

Im Vergleich zu klassischen relationalen Datenbanksystemen stellt das RDF-Datenmodell die Anfrageoptimierung vor neuartige Herausforderungen. Diese resultieren sowohl aus der schemalosen und semistrukturierten Natur von RDF als auch aus der offenen Semantik, wie sie durch die Open World Assumption (OWA) definiert wird. In diesem Kapitel werden zentrale Optimierungsprobleme analysiert, die bei der Ausführung von SPARQL-Anfragen in RDF-Datenbanken typischerweise auftreten.

\subsection{Fehlende Schemata und begrenzte Ontologien}

RDF-Datenbanken verfügen typischerweise über kein fixes, global definiertes Schema. Im Gegensatz zu relationalen Datenbanken, in denen die Struktur der Daten über Tabellen- und Attributdefinitionen klar vorgegeben ist, liegt RDF-Daten meist keine explizite Schemadefinition zugrunde. Zwar können optionale semantische Erweiterungen durch Ontologien in RDFS oder OWL eingebunden werden, doch sind diese in der Praxis häufig zu generisch, unvollständig oder nicht konsistent gepflegt. Dadurch fehlen dem Optimierer wesentliche Informationen, etwa über Kardinalitäten, Schlüssel oder Typverteilungen \cite{harth2010sparqling}.

\subsection{Hohe Joindichte bei einfachen Anfragen}

Ein charakteristisches Merkmal von SPARQL-Anfragen ist ihre Joindichte: Selbst einfache Informationsabfragen bestehen aus mehreren Tripelmustern, die über Variablen verknüpft sind. So entspricht z.\,B. eine Abfrage wie „Welche Autoren haben Bücher veröffentlicht, die 2020 erschienen sind?“ bereits einem mehrstufigen Join über die Tripel \texttt{(?book dc:creator ?author)}, \texttt{(?book dc:date ?year)} und \texttt{FILTER (?year = 2020)}. In relationalen Datenbanken könnten solche Informationen in einer einzigen, gut indizierten Tabelle abgefragt werden, während RDF-Systeme mehrere Tripelrelationen verbinden müssen.

Die effiziente Bestimmung der optimalen Join-Reihenfolge ist bei hoher Joindichte besonders anspruchsvoll, da die Anzahl möglicher Join-Bäume exponentiell mit der Anzahl der Tripelpattern wächst \cite{gubichev2013sparql}.

\subsection{Fehlende Kardinalitätsabschätzungen}

Ein zentrales Problem bei der Optimierung ist die fehlende oder ungenaue Schätzung der Kardinalitäten einzelner Tripelpattern. Während relationale Optimierer häufig auf detaillierte Statistiken über Werteverteilungen, Indizes und Histogramme zurückgreifen können, sind entsprechende Metainformationen in RDF-Systemen selten vorhanden oder ungenau. Dies liegt u.\,a. an der extrem heterogenen Nutzung von Prädikaten und an der typischen „long tail“-Verteilung von Vokabularen – viele Prädikate treten sehr selten auf, während wenige sehr häufig vorkommen \cite{stahl2012rdf}.

Falsche Kardinalitätsschätzungen führen in kostenbasierten Optimierern regelmäßig zu suboptimalen Ausführungsplänen, insbesondere bei mehrfach geschachtelten Joins oder OPTIONAL-Konstrukten.

\subsection{Einfluss der Open World Assumption (OWA)}

Die OWA wirkt sich fundamental auf Optimierungsstrategien aus. Da das Fehlen einer Aussage nicht bedeutet, dass sie falsch ist, sind Optimierungen wie Filter-Pushdown, Join-Eliminierung oder Ergebnisvorhersage nur eingeschränkt anwendbar. Besonders bei OPTIONAL-Blöcken ist die semantische Bedeutung komplex: Das Weglassen eines Tripels kann valide sein, auch wenn dadurch keine vollständige Bindung entsteht. Optimierer müssen also Worst-Case-Szenarien einkalkulieren, was zu konservativen und ineffizienten Plänen führen kann.

\subsection{Komplexe SPARQL-Konstrukte: OPTIONAL, FILTER, UNION}

SPARQL bietet mit Konstrukten wie \texttt{OPTIONAL}, \texttt{FILTER} und \texttt{UNION} mächtige Ausdrucksmittel, die jedoch die Optimierung erheblich erschweren. OPTIONAL erzeugt implizit einen left outer join, wodurch bestimmte Join-Reihenfolgen ausgeschlossen werden. FILTER-Ausdrücke, insbesondere wenn sie auf BIND-Ergebnisse oder externe Funktionen zugreifen, lassen sich häufig nicht vorziehen oder aufteilen. UNIONs hingegen führen zu mehrfachen Teilplänen mit potenziell überlappenden Ergebnissen.

Ein einfaches Beispiel ist eine Anfrage nach Geburtsdaten oder Sterbedaten prominenter Persönlichkeiten:

\begin{lstlisting}[caption=Beispiel: OPTIONAL-Abfrage in SPARQL]
SELECT ?person ?birth ?death WHERE {
  ?person dbo:birthDate ?birth .
  OPTIONAL { ?person dbo:deathDate ?death . }
}
\end{lstlisting}

Ein naiver Optimierer könnte das OPTIONAL-Muster ungünstig an den Anfang des Ausführungsplans setzen, was zu deutlich schlechterer Performance führt.

\subsection{Strukturelle Probleme: Blank Nodes und Named Graphs}

Blank Nodes – also Ressourcen ohne URI – erschweren das Identifizieren und Joins über Entitäten. Da sie nicht global referenzierbar sind, müssen sie intern durch systemgenerierte Identifikatoren ersetzt werden. Dies erschwert insbesondere Inferenzmechanismen und die Nachverfolgbarkeit von Aussagen.

Named Graphs wiederum erlauben die Gruppierung von Tripeln in kontextuelle Teilgraphen. Zwar bietet dies konzeptionelle Vorteile (z.\,B. zur Provenienz oder Versionierung), doch führt dies in der Optimierung zu zusätzlichem Planungsaufwand, da Anfragen graphübergreifend analysiert werden müssen.

% ---------------------- Kapitel 5 ------------------------
\section{Optimierungsansätze im RDF-Kontext} \label{sec:ansaetze}

Angesichts der strukturellen und semantischen Herausforderungen von RDF-Datenbanken wurden in den letzten Jahren zahlreiche Optimierungsstrategien entwickelt, die speziell auf die Besonderheiten graphbasierter Datenmodelle zugeschnitten sind. Einige davon orientieren sich an Prinzipien aus der relationalen Welt, andere greifen auf neue Konzepte zurück. Dieses Kapitel gibt einen systematischen Überblick über zentrale Optimierungsmethoden und ordnet sie in Bezug auf ihre Einsatzbedingungen und Wirksamkeit ein.

\subsection{Heuristikbasierte Optimierung}

Viele RDF-Engines, insbesondere Open-Source-Systeme wie Apache Jena oder Eclipse RDF4J (ehemals Sesame), implementieren heuristische Optimierungen, um typische Anfragen effizienter zu verarbeiten. Dabei kommen einfache Regeln zum Einsatz, die unabhängig von detaillierten Statistiken funktionieren.

Ein zentrales Prinzip ist die Reorganisation der Tripelpattern: Selektive Muster – also solche mit häufigen Konstanten oder spezifischen Prädikaten – werden möglichst weit vorne im Anfragebaum verarbeitet. Dadurch kann die Bindungsmenge früh reduziert werden, was sich auf nachfolgende Joins positiv auswirkt. Ebenfalls etabliert ist der sogenannte \textit{Filter Pushdown}, bei dem FILTER-Ausdrücke so nah wie möglich an die Datensätze verschoben werden, auf die sie sich beziehen \cite{yuan2015heuristics}.

Ein typisches Beispiel ist die Umstrukturierung folgender Anfrage:

\begin{lstlisting}[caption=Unoptimierte vs. heuristisch optimierte Reihenfolge von Tripeln]
# Unoptimiert:
?x dbo:birthPlace ?place .
?x rdf:type dbo:Person .
?x foaf:name ?name .

# Optimiert:
?x rdf:type dbo:Person .
?x foaf:name ?name .
?x dbo:birthPlace ?place .
\end{lstlisting}

Hierbei wird angenommen, dass `rdf:type` eine stark selektive Einschränkung darstellt und daher zuerst evaluiert werden sollte.

\subsection{Kostenbasierte Optimierung}

Komplexere RDF-Datenbanken wie Virtuoso oder Blazegraph nutzen kostenbasierte Optimierer, die verschiedene Anfragepläne bewerten und auf Basis geschätzter Ausführungskosten den effizientesten Plan wählen. Ähnlich wie in relationalen Systemen stützt sich dieser Prozess auf Statistiken über Prädikatsverteilungen, Kardinalitäten und Wertfrequenzen \cite{sequeda2014cost}.

Besonderheiten ergeben sich jedoch aus der Struktur der Daten: RDF-Prädikate verhalten sich nicht wie feste Spalten, sondern können sehr unterschiedlich interpretiert und verteilt sein. Moderne Systeme greifen daher zu Hybridstrategien, bei denen heuristische Vorauswahl mit statistischer Bewertung kombiniert wird.

Ein Beispiel ist die Abfrage nach allen Akteuren eines Films, bei der JOINs über `dbo:starring`, `dbo:director`, `dbo:releaseDate` und weitere Prädikate erforderlich sind. Ein Optimierer wählt dabei nicht nur die Join-Reihenfolge, sondern berücksichtigt auch, welche Teilpläne potenziell hohe Kosten verursachen (z.\,B. bei großen Bindungsräumen oder UNION-Konstrukten).

\subsection{Strukturbasierte Optimierung nach Graphmustern}

Neuere Forschungsarbeiten klassifizieren SPARQL-Anfragen nach ihrer strukturellen Form – z.\,B. als Sterne (ein zentrales Subjekt mit mehreren Prädikaten), Pfade (verkettete Prädikate), Bäume oder Zyklen. Diese Muster lassen sich nutzen, um Anfragen gezielt zu zerschneiden oder zusammenzufassen.

Ein Sternmuster wie:

\begin{lstlisting}[caption=Sternförmiges SPARQL-Muster]
?person foaf:name ?name ;
        dbo:birthDate ?birth ;
        dbo:deathDate ?death ;
        dbo:occupation ?job .
\end{lstlisting}

ermöglicht die Bündelung der Prädikate in sogenannten \textit{Property Tables} oder erlaubt parallele Verarbeitung durch semantisches Partitionieren \cite{akhtar2019structure}. Für Pfade wiederum kann ein sogenannter \textit{Path Index} erzeugt werden, der häufige Prädikatssequenzen vorab berechnet und indiziert.

\subsection{Speicherstruktur und physische Repräsentation}

Die physische Speicherung hat erheblichen Einfluss auf die Effizienz der Anfrageverarbeitung. Während einfache RDF-Systeme eine klassische Tripel-Tabelle (Subjekt, Prädikat, Objekt) nutzen, greifen optimierte Systeme auf spezialisierte Layouts zurück:

\begin{itemize}
    \item \textbf{Vertical Partitioning:} Eine separate Tabelle je Prädikat. Vorteilhaft für selektive Prädikatsanfragen, jedoch Join-intensiv.
    \item \textbf{Property Tables:} Gruppierung häufig gemeinsam auftretender Prädikate in eine Zeile – ähnlich einer relationalen Projektion.
    \item \textbf{Hexastore:} Speicherung aller sechs Permutationen von SPO (z.\,B. POS, OSP etc.), um beliebige Zugriffsmuster effizient zu unterstützen \cite{weiss2008hexastore}.
\end{itemize}

Die Wahl der Speicherstruktur beeinflusst unmittelbar die Indexierung, Join-Kosten und Parallelisierbarkeit.

\subsection{Kompilierung in relationale Ausführungspläne}

Einige Systeme nutzen sogenannte R2RML-Mappings, um RDF-Daten auf relationale Strukturen abzubilden. SPARQL-Anfragen werden dabei in SQL überführt, sodass bestehende relationale Optimierer (z.\,B. aus PostgreSQL) genutzt werden können. Voraussetzung ist jedoch eine wohldefinierte Ontologie oder Mapping-Tabelle. Beispiele für derartige Systeme sind Ontop oder D2RQ.

Vorteilhaft ist dabei die Wiederverwendbarkeit bewährter SQL-Techniken; allerdings leidet die Flexibilität bei der Abbildung komplexer RDF-Graphenstrukturen.

\subsection{Materialisierung und Vorberechnung}

Zur Verbesserung der Performance bei häufigen Abfragen kommen in RDF-Systemen zunehmend materialisierte Views zum Einsatz. Dabei handelt es sich um vorab berechnete Antwortmengen oder Teilergebnisse, die zur Laufzeit direkt verwendet werden können. Insbesondere bei bekannten Mustern – etwa rekursiven Beziehungen oder häufigen Joinketten – lohnt sich die Vorberechnung \cite{elzein2019materialized}.

Alternativ können semantische Indizes über Subklassen, Subproperties oder Instanzen erzeugt werden, um Inferenzkosten zur Laufzeit zu vermeiden.

\subsection{Ontologiebasierte Anfrageumschreibung}

Schließlich ermöglichen Ontologien eine semantische Erweiterung der Anfrageverarbeitung. In sogenannten \textit{ontology-aware systems} werden SPARQL-Anfragen automatisch um Regeln ergänzt, die sich aus OWL-Axiomen ableiten. Beispielsweise kann bei einer Anfrage nach `dbo:University` auch nach Subklassen wie `dbo:TechnicalUniversity` gesucht werden, ohne dass dies explizit formuliert wurde \cite{tsatsanifos2012ontologies}.

Problematisch ist jedoch, dass komplexe Ontologien zu einer exponentiellen Erweiterung des Anfragebaums führen können, was die Optimierung massiv erschwert. In der Praxis ist daher häufig eine Mischung aus statischer Inferenz (Materialisierung) und dynamischer Umschreibung (Rewriting) anzutreffen.

% ---------------------- Kapitel 6 ------------------------
\section{Vergleich mit klassischen Optimierungskonzepten} \label{sec:vergleich}

Die Optimierung von SPARQL-Anfragen in RDF-Datenbanken steht in enger Beziehung zur traditionellen Anfrageoptimierung in relationalen Datenbanksystemen. Viele grundlegende Prinzipien lassen sich auf den RDF-Kontext übertragen, müssen jedoch an die semantische und graphenorientierte Struktur des Datenmodells angepasst werden. In diesem Kapitel werden zentrale Gemeinsamkeiten und Unterschiede analysiert, insbesondere im Hinblick auf das Modell der \textit{Intensional Database (IDB)} und \textit{Extensional Database (EDB)}, wie es in logikbasierten Systemen etabliert ist.

\subsection{Gemeinsamkeiten}

Sowohl relationale als auch RDF-basierte Systeme verfolgen das Ziel, aus einer logischen Anfrage einen möglichst effizienten Ausführungsplan zu erzeugen. In beiden Fällen kommen ähnliche Optimierungsstrategien zum Einsatz:

\begin{itemize}
    \item \textbf{Anfragealgebra:} Relationale Systeme nutzen die relationale Algebra, RDF-Systeme arbeiten intern mit Graphpattern-Bäumen, die algebraisch transformiert werden können \cite{perez2009semantics}.
    \item \textbf{Join-Optimierung:} Die Reihenfolge von Joins hat großen Einfluss auf die Laufzeit. Dynamische Programmierung (z.\,B. nach Selinger) oder heuristische Verfahren finden in beiden Bereichen Anwendung.
    \item \textbf{Indexierung:} Beide Systemtypen verwenden Indizes zur Beschleunigung des Zugriffs. In RDF-Systemen kommen zusätzlich Hexastore- oder Bitmap-Indizes zum Einsatz.
    \item \textbf{Kostenmodelle:} Sowohl in SQL- als auch in SPARQL-Engines existieren kostenbasierte Optimierer, die geschätzte Ausführungskosten vergleichen.
\end{itemize}

\subsection{Unterschiede}

Trotz dieser Ähnlichkeiten ergeben sich erhebliche Unterschiede, die sich direkt auf die Optimierungsverfahren auswirken:

\begin{itemize}
    \item \textbf{Schema vs. Ontologie:} Relationale Datenbanken verfügen über ein explizites, vollständiges Schema. RDF hingegen ist schemalos und optional semantisch über Ontologien ergänzt. Dies erschwert Kardinalitätsschätzungen, Typableitungen und Indexnutzung.
    
    \item \textbf{Closed World Assumption vs. Open World Assumption:} In SQL gilt: Was nicht gespeichert ist, ist falsch. In SPARQL (unter OWA): Was nicht bekannt ist, ist potenziell wahr. Dadurch verlieren viele Optimierungsregeln ihre Gültigkeit, z.\,B. Join-Eliminierung oder Negationsvereinfachung.
    
    \item \textbf{Datenmodell:} Während das relationale Modell auf Tabellen mit festen Attributen basiert, nutzt RDF ein graphenbasiertes Tripelmodell. Dies führt zu Joins auf einer generischen Relation (Tripelstruktur), was die Ausführungskosten für komplexe Abfragen signifikant erhöht.
    
    \item \textbf{Abfragesprachen:} SQL ist weitgehend vollständig algebraisch beschreibbar, SPARQL enthält Konstrukte wie OPTIONAL, MINUS und PROPERTY PATHS, die nicht direkt in klassische Algebren abbildbar sind.
\end{itemize}

\subsection{IDB/EDB-Konzepte im RDF-Kontext}

Die Unterscheidung in EDB (Extensional Database, also Basisdaten) und IDB (Intensional Database, abgeleitete Daten durch Regeln) stammt aus der Datalog-Theorie. Diese Trennung findet im RDF-Bereich Entsprechungen bei der Verwendung von Regeln und Inferenz.

Beispielsweise können RDF-Inferenzsysteme wie Apache Jena durch RDFS- oder OWL-Regeln neue Tripel ableiten – etwa durch Subklassenrelationen oder transitive Eigenschaften. Diese „abgeleiteten“ Aussagen entsprechen IDB-Fakten. Die Basisdaten hingegen – d.\,h. die ursprünglich geladenen Tripel – stellen die EDB dar.

Ein Beispiel für transitive Inferenz:

\begin{lstlisting}[caption=Beispiel für abgeleitete Tripel durch Inferenz]
ex:A ex:partOf ex:B .
ex:B ex:partOf ex:C .

# abgeleitet (transitiv):
ex:A ex:partOf ex:C .
\end{lstlisting}

Für die Optimierung bedeutet dies, dass Anfragepläne sowohl die gespeicherten als auch die abgeleiteten Tripel berücksichtigen müssen – idealerweise mit vorberechneten (materialisierten) Schlussfolgerungen oder durch Anfrageumschreibung \cite{motik2007sparql}.

\subsection{Zusammenfassung der Unterschiede}

\vspace{0.5em}
\begin{table}[h]
\centering
\caption{Vergleich relationaler und RDF-basierter Optimierung}
\begin{tabular}{|p{4.5cm}|p{5cm}|p{5cm}|}
\hline
\textbf{Aspekt} & \textbf{Relationale DB} & \textbf{RDF-Datenbank} \\
\hline
Datenmodell & Tabellen mit Attributen & Graph aus Tripeln \\
Schema & festes, geschlossenes Schema & optional via Ontologie, offen \\
Weltannahme & Closed World & Open World \\
Abfragesprache & SQL & SPARQL \\
Optimierung & algebraisch, kostenbasiert & heuristisch, kostenbasiert, strukturell \\
IDB/EDB-Unterstützung & in Datalog, rekursiv möglich & durch Inferenzsysteme und OWL \\
\hline
\end{tabular}
\end{table}


% ---------------------- Kapitel 7 ------------------------
\section{Diskussion} \label{sec:diskussion}

Die vorangegangenen Kapitel haben gezeigt, dass die Optimierung von SPARQL-Anfragen im RDF-Kontext wesentlich komplexer ist als im klassischen relationalen Umfeld. In der Diskussion sollen zentrale Herausforderungen nochmals kritisch beleuchtet, offene Problemfelder aufgezeigt und die praktischen Implikationen dieser Unterschiede eingeordnet werden.

\subsection{Grenzen klassischer Optimierung im semantischen Kontext}

Ein zentrales Ergebnis ist, dass viele bewährte Optimierungsprinzipien aus der relationalen Welt – insbesondere kostenbasierte Modelle, algebraische Transformationen und Indexstrategien – zwar grundsätzlich übertragbar, aber im RDF-Kontext nicht ohne Anpassungen wirksam sind. Der entscheidende Unterschied liegt im Datenmodell: Während relationale Daten durch ein festes Schema klar strukturiert sind, folgt RDF einem offenen, flexiblen und semantisch angereicherten Graphmodell.

Diese Offenheit wirkt sich negativ auf die Planbarkeit aus: Ohne verbindliche Kardinalitäten, eindeutige Schlüsselkandidaten oder vollständige Wertverteilungen lassen sich kaum präzise Kostenmodelle erstellen. Dies betrifft insbesondere komplexe SPARQL-Anfragen mit UNION, OPTIONAL oder FILTER-Klauseln. Die im RDF-Umfeld notwendige Trennung zwischen syntaktischer Anfrage und semantischer Interpretation erschwert zusätzlich die Anwendung herkömmlicher Optimierungstechniken \cite{nourie2021survey}.

\subsection{Bedeutung von Inferenz und OWA}

Ein weiterer Aspekt, der Optimierungsverfahren fundamental beeinflusst, ist die Open World Assumption. Inferenzmechanismen, wie sie über OWL oder RDFS realisiert werden, erzeugen zur Laufzeit neue Fakten, die nicht explizit in den Rohdaten enthalten sind. Optimierer müssen daher nicht nur gespeicherte Daten, sondern auch potenziell ableitbare Informationen berücksichtigen – entweder durch Materialisierung oder dynamisches Rewriting.

Dieser Umstand führt zu einer Verschiebung der Komplexität: Statt die Anfrageausführung zu beschleunigen, muss der Optimierer entscheiden, welche Teile der Anfrage durch Regeln erweitert werden können oder müssen. Je größer die Ontologie, desto höher ist die Gefahr einer exponentiellen Explosion des Anfragebaums \cite{tsatsanifos2012ontologies}. In der Praxis führt dies dazu, dass viele Systeme Inferenz auf bestimmte Profile beschränken (z.\,B. OWL RL), um Optimierbarkeit zu gewährleisten.

\subsection{Praktische Relevanz vs. Forschungskomplexität}

Obwohl viele der genannten Optimierungsprobleme in der Forschung ausführlich analysiert wurden, zeigt sich in der Praxis ein oft starker Kontrast: Produktionssysteme wie Virtuoso, Blazegraph oder GraphDB setzen meist auf pragmatische Hybridlösungen aus Heuristiken, einfachen Statistiken und Caching. Vollständige Ontologie-Reasoner oder kostenbasierte Multistrategie-Optimierer sind selten implementiert oder nur in akademischen Prototypen zu finden.

Dies verdeutlicht die bestehende Lücke zwischen theoretisch möglichen Verfahren und praktisch einsatzfähigen Lösungen. Gründe dafür liegen in der Skalierungsproblematik, der mangelnden Standardisierung und den oft stark domänenspezifischen Datenstrukturen im Semantic Web.

\subsection{Offene Forschungsfragen}

Trotz zahlreicher Beiträge bleiben wesentliche Fragen offen. Dazu zählen:
\begin{itemize}
    \item Wie lassen sich Kardinalitätsschätzungen bei schemalosen RDF-Daten zuverlässiger gestalten?
    \item Welche Rolle können lernbasierte Optimierer (z.\,B. via Reinforcement Learning oder Graph-Neural-Networks) in dynamischen RDF-Umgebungen spielen?
    \item Wie kann die Integration von Inferenz und Anfrageoptimierung effizient organisiert werden, ohne dabei auf semantische Tiefe zu verzichten?
    \item Ist ein universell adaptierbares Kostenmodell für SPARQL realistisch oder müssen daten- bzw. domänenspezifische Modelle entwickelt werden?
\end{itemize}

Diese Fragen zeigen, dass die Anfrageoptimierung im RDF-Kontext ein aktives Forschungsfeld bleibt, in dem klassische Datenbankkonzepte zwar eine wichtige Grundlage bilden, jedoch nicht ausreichen, um die Herausforderungen semantischer Graphdaten vollständig zu bewältigen.

% ---------------------- Kapitel 8 ------------------------ 

\section{Fazit und Ausblick} \label{sec:fazit}

Ziel dieser Arbeit war es, einen systematischen Überblick über Optimierungsstrategien für SPARQL-Anfragen im RDF-Kontext zu geben und diese mit klassischen Konzepten der relationalen Anfrageverarbeitung zu vergleichen. Ausgangspunkt war die Beobachtung, dass RDF-basierte Systeme aufgrund ihrer semistrukturierten, schemalosen und semantisch offenen Natur erheblich komplexere Anforderungen an die Anfrageoptimierung stellen als relationale Datenbanksysteme.

Im Verlauf der Analyse zeigte sich, dass viele Prinzipien aus der relationalen Optimierung – wie Join-Reihenfolgenplanung, Filter-Pushdown, oder kostenbasierte Auswahl von Ausführungsplänen – grundsätzlich übertragbar sind. Ihre konkrete Umsetzung im RDF-Umfeld erfordert jedoch erhebliche Anpassungen. Besonders herausfordernd sind die fehlenden Schemainformationen, die hohe Joindichte selbst einfacher SPARQL-Anfragen und die offene Weltannahme, die klassische Optimierungsmuster teilweise außer Kraft setzt.

Die untersuchten Optimierungsansätze reichen von einfachen Heuristiken über struktur- und kostenbasierte Verfahren bis hin zu semantikbasierten Techniken wie Inferenzumschreibungen und Vorberechnungen. Systeme wie Virtuoso, Blazegraph oder Apache Jena nutzen in der Praxis meist hybride Verfahren, um zwischen Effizienz, Vollständigkeit und semantischer Korrektheit zu balancieren.

Der Vergleich mit klassischen Optimierungskonzepten hat gezeigt, dass RDF-Systeme trotz konzeptioneller Unterschiede viele bewährte Methoden adaptieren können – etwa in Form von SPARQL-Algebren, statischer Indexierung oder materialisierter Views. Das IDB/EDB-Konzept findet sich in der Trennung zwischen gespeicherten und abgeleiteten Tripeln wieder, etwa durch OWL-Inferenz oder Regelanwendungen. Dennoch bleibt die Optimierung im RDF-Kontext deutlich stärker von Kontext, Ontologieumfang und Anwendungsdomäne abhängig.

\subsection*{Ausblick}

Die Anfrageoptimierung im RDF-Kontext bleibt ein hochaktuelles und herausforderndes Forschungsfeld. Insbesondere folgende Entwicklungslinien erscheinen vielversprechend:

\begin{itemize}
    \item \textbf{Lernbasierte Optimierung:} Der Einsatz von Machine-Learning-Ansätzen zur Kardinalitätsschätzung, Join-Reihenfolgenbestimmung und Planvorhersage könnte bestehende Heuristiken ergänzen oder ersetzen.
    
    \item \textbf{Adaptive Systeme:} Zukünftige RDF-Engines sollten in der Lage sein, sich automatisch an neue Datenstrukturen und Anfrageprofile anzupassen – etwa durch kontinuierliches Feedback oder Workload-Analysen.
    
    \item \textbf{Inferenz-aware Optimization:} Die enge Verzahnung von semantischer Schlussfolgerung und Anfrageplanung könnte optimiert werden, etwa durch hybride Ansätze aus Materialisierung und dynamischem Rewriting.
    
    \item \textbf{Standardisierung und Benchmarking:} Vergleichbare, realistische Benchmarks für SPARQL-Optimierung sind essenziell, um neue Ansätze systematisch evaluieren zu können.
\end{itemize}

Langfristig wird die semantische Datenverarbeitung nur dann skalierbar und praxistauglich sein, wenn Anfrageoptimierung nicht als rein technisches Problem, sondern als integraler Bestandteil semantischer Datenmodellierung verstanden wird.


\printbibliography

\end{document}
